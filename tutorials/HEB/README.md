
# ğŸ¤— ×¢×¨×›×ª ×›×œ×™× ×œ×—×™× ×•×š
<span dir="rtl" align="right">

<aside>

ğŸ‘‹ **×‘×¨×•×›×™× ×”×‘××™×!**

×”×›× ×• ×¢×¨×›×” ×©××“×¨×™×›×™× ×‘××•× ×™×‘×¨×¡×™×˜×” ×™×›×•×œ×™× ×œ×”×©×ª××© ×‘×” ×›×“×™ ×œ×”×›×™×Ÿ ×‘×§×œ×•×ª ××¢×‘×“×•×ª, ×©×™×¢×•×¨×™ ×‘×™×ª, ××• ××¢×¨×›×™ ×©×™×¢×•×¨. ×ª×•×›×Ÿ ×–×” ×”×•× **×‘×—×™× ×** ×•××©×ª××© ×‘×˜×›× ×•×œ×•×’×™×•×ª ×§×•×“ ×¤×ª×•×— ××•×›×¨×•×ª (`transformers`, `gradio`, ×•×›×•').

×œ×—×œ×•×¤×™×Ÿ, ××¤×©×¨ ×œ×‘×§×© ×©××™×©×”×• ××¦×•×•×ª Hgging Face ×™×¨×™×¥ ××ª ×”×”×“×¨×›×•×ª ×œ×›×™×ª×” ×©×œ×›× ×“×¨×š ×™×•×–××ª ×” - [ML demo.cratization tour](https://www.notion.so/ML-Demo-cratization-tour-with-66847a294abd4e9785e85663f5239652) !

×‘× ×•×¡×£ ×œ×”×“×¨×›×•×ª, ×× ×—× ×• ×—×•×œ×§×™× ××©××‘×™× × ×•×¡×¤×™× ×©×××¤×©×¨×™× ×œ×¦×œ×•×œ ×¢×•×“ ×œ×¢×•×œ× ×œ××™×“×ª ×”××›×•× ×” (ML), ×•×©×™×›×•×œ×™× ×œ×¡×™×™×¢ ×‘×ª×›× ×•×Ÿ ×ª×•×›×Ÿ ×”×§×•×¨×¡.

</aside>

×ª×¨×’×•××™× ×©×œ ×”×”×“×¨×›×•×ª ×œ×©×¤×•×ª × ×•×¡×¤×•×ª ××¤×©×¨ ×œ××¦×•× [×›××Ÿ!](https://github.com/huggingface/education-toolkit#-languages-and-translations)

## **×§×˜×œ×•×’ ×”×”×“×¨×›×•×ª ×©×œ× ×•**

### 1ï¸âƒ£Â ×¡×™×•×¨ ×“×¨×š ×” - Hugging Face Hub

> ×‘×”×“×¨×›×” ×–×•, ×ª×•×›×œ×•: 
> 
> - ×œ×—×§×•×¨ ××ª ×™×•×ª×¨ × 30,000 ×”××•×“×œ×™× ×©×©×•×¤×• ×‘ - Hub
> - ×œ×œ××•×“ ×“×¨×›×™× ×™×¢×™×œ×•×ª ×œ××¦×•× ××ª ×”××•×“×œ ×•××ª ×” - datasets ×”× ×›×•× ×™×.
> - ×œ×œ××•×“ ××™×š ×œ×©×ª×£ ×•××™×š ×œ×¢×‘×•×“ ×‘×©×™×ª×•×£ ×¤×¢×•×œ×” ×‘ ML workflow ×©×œ×›×.
>
> **××©×š ×”×”×“×›×”: 20-40 ×“×§×•×ª**
>
> ğŸ‘ˆÂ [×œ×—×¦×• ×›××Ÿ ×›×“×™ ×œ×’×©×ª ×œ×”×“×¨×›×”](https://www.notion.so/Workshop-A-Tour-through-the-Hugging-Face-Hub-2098e4bae9ba4288857e85c87ff1c851) ××• ğŸ‘©â€ğŸ« [×œ×©×§×•×¤×™×•×ª ×”×”×¨×¦××”](https://docs.google.com/presentation/d/1zQqpFTcpNLV7haj2Inw2qKHq8DjfZEaiObW1ZkLvPWM/edit?usp=sharing).

### 2ï¸âƒ£Â Build and Host Machine Learning Demos with Gradio & Hugging Face

> In this tutorial, you get to:
>
> - Explore ML demos created by the community.
> - Build a quick demo for your machine learning model in Python using theÂ `gradio`Â library
> - Host the demos for free with Hugging Face Spaces
> - Add your demo to the Hugging Face org for your class or conference
>
> **_Duration: 20-40 minutes_**
>
> ğŸ‘ˆÂ [click here to access the tutorial](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/tutorials/EN/02_ml-demos-with-gradio.ipynb) or ğŸ‘©â€ğŸ« [the lecture slides](https://docs.google.com/presentation/d/14EU_xjtINXtpidWLnUvfcEpmxN46ORS-PLpwfUf8C1I/edit?usp=sharing).

### 3ï¸âƒ£Â Getting Started with Transformers

> In this tutorial, you get to:
>
> - Transformer neural networks can be used to tackle a wide range of tasks in natural language processing and beyond.
> - Transfer learning allows one to adapt Transformers to specific tasks.
> - TheÂ `pipeline()`Â function from theÂ `transformers`Â library can be used to run inference with models from theÂ [Hugging Face Hub](https://huggingface.co/models).
>
> This tutorial is based on the first of our O'Reilly bookÂ *[Natural Language Processing with Transformers](https://transformersbook.com/)*Â - check it out if you want to dive deeper into the topic!
>
> **_Duration: 30-45 minutes_**
>
> ğŸ‘ˆÂ [click here to access the tutorial](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/tutorials/EN/03_getting-started-with-transformers.ipynb)

## **Other resources to learn your way!**

### **The ğŸ¤—Â Course**

We provide a course (free and without ads) that teaches you about natural language processing (NLP) using libraries from theÂ **[Hugging Face](https://huggingface.co/)** ecosystem.

ğŸ‘ˆÂ [click here to access the ğŸ¤—Â Course](https://huggingface.co/course/chapter1/1)

<aside>
ğŸ’¡ This course:

- Requires good knowledge of Python
- Is better taken after an introductory deep learning course, such asÂ **[fast.aiâ€™s](https://www.fast.ai/)**Â **[Practical Deep Learning for Coders](https://course.fast.ai/)**Â or one of the programs developed byÂ **[DeepLearning.AI](https://www.deeplearning.ai/)**
- Does not expect priorÂ **[PyTorch](https://pytorch.org/)**Â orÂ **[TensorFlow](https://www.tensorflow.org/)**Â knowledge, though some familiarity with either of those will help
</aside>

### **The ğŸ¤—Â Book**

<img alt="book-cover" height=200 src="../../images/book_cover.jpg" id="book-cover"/>

Released February 2022

From experts at Hugging Face, learn all about Transformers and their applications to a wide range of NLP tasks.

ğŸ‘ˆÂ [click here to visit the bookâ€™s website](https://transformersbook.com/)

<aside>
ğŸ’¡ This book:

- Is written for data scientists and machine learning engineers who may have heard about the recent breakthroughs involving transformers, but are lacking an in-depth guide to help them adapt these models to their own use cases.
- Assumes you have some practical experience with training models on GPUs.
- Does not expect priorÂ **[PyTorch](https://pytorch.org/)**Â orÂ **[TensorFlow](https://www.tensorflow.org/)**Â knowledge, though some familiarity with either of those will help
</aside>


## ğŸŒ Translations

| Language | Source | Contributors |
|:---:|:---:|---|
| Spanish | [ `tutorials/ES` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/ES ) | @[lewtun](https://github.com/lewtun), @[osanseviero](https://github.com/osanseviero), @[omarespejel](https://github.com/omarespejel), @[Fabioburgos](https://github.com/Fabioburgos) |
| Japanese | [ `tutorials/JA` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/JA ) | @[Wataru-Nakata](https://github.com/Wataru-Nakata) |
| Turkish (TR) | [ `tutorials/TR` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/TR ) | @[emrecgty](https://github.com/emrecgty/) @[farukozderim](https://github.com/FarukOzderim/)  |
| Portuguese (WIP) | [ `tutorials/PT` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/PT ) |  |

If you would like to translate the tutorials to your language, see our [TRANSLATING](https://github.com/huggingface/education-toolkit#-languages-and-translations/TRANSLATING.md) guide.

<aside>
âœ‰ï¸ If you have any questions, please contact violette@huggingface.co!

</aside>
</span>