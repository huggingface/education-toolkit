# 🤗 Education Toolkit

<aside>

👋 **ברוכים הבאים!**

הכנו ערכה שמדריכים באוניברסיטה יכולים להשתמש בה כדי להכין בקלות מעבדות, שיעורי בית, או מערכי שיעור. תוכן זה הוא **בחינם** ומשתמש בטכנולוגיות קוד פתוח מוכרות (`transformers`, `gradio`, וכו').

Alternatively, you can request for someone on the Hugging Face team to run the tutorials for your class via the [ML demo.cratization tour](https://www.notion.so/ML-Demo-cratization-tour-with-66847a294abd4e9785e85663f5239652) initiative!

Apart from tutorials, we also share other resources to go further into ML or that can assist in designing course content.

</aside>

Would you like to find the tutorials in other languages? You can find all the translations [here!](https://github.com/huggingface/education-toolkit#-languages-and-translations)

## **Our Tutorials Catalog**

### 1️⃣ A Tour through the Hugging Face Hub

> In this tutorial, you get to:
>
> - Learn efficient ways to find the right model and datasets for your own task.
> - Learn how to contribute and work collaboratively in your ML workflows
>
> **_Duration: 20-40 minutes_**
>
> 👉 [click here to access the tutorial](https://www.notion.so/Workshop-A-Tour-through-the-Hugging-Face-Hub-2098e4bae9ba4288857e85c87ff1c851) or 👩‍🏫 [the lecture slides](https://docs.google.com/presentation/d/1zQqpFTcpNLV7haj2Inw2qKHq8DjfZEaiObW1ZkLvPWM/edit?usp=sharing).

### 2️⃣ Build and Host Machine Learning Demos with Gradio & Hugging Face

> In this tutorial, you get to:
>
> - Explore ML demos created by the community.
> - Build a quick demo for your machine learning model in Python using the `gradio` library
> - Host the demos for free with Hugging Face Spaces
> - Add your demo to the Hugging Face org for your class or conference
>
> **_Duration: 20-40 minutes_**
>
> 👉 [click here to access the tutorial](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/tutorials/EN/02_ml-demos-with-gradio.ipynb) or 👩‍🏫 [the lecture slides](https://docs.google.com/presentation/d/14EU_xjtINXtpidWLnUvfcEpmxN46ORS-PLpwfUf8C1I/edit?usp=sharing).

### 3️⃣ Getting Started with Transformers

> In this tutorial, you get to:
>
> - Transformer neural networks can be used to tackle a wide range of tasks in natural language processing and beyond.
> - Transfer learning allows one to adapt Transformers to specific tasks.
> - The `pipeline()` function from the `transformers` library can be used to run inference with models from the [Hugging Face Hub](https://huggingface.co/models).
>
> This tutorial is based on the first of our O'Reilly book *[Natural Language Processing with Transformers](https://transformersbook.com/)* - check it out if you want to dive deeper into the topic!
>
> **_Duration: 30-45 minutes_**
>
> 👉 [click here to access the tutorial](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/tutorials/EN/03_getting-started-with-transformers.ipynb)

## **Other resources to learn your way!**

### **The 🤗 Course**

We provide a course (free and without ads) that teaches you about natural language processing (NLP) using libraries from the **[Hugging Face](https://huggingface.co/)** ecosystem.

👉 [click here to access the 🤗 Course](https://huggingface.co/course/chapter1/1)

<aside>
💡 This course:

- Requires good knowledge of Python
- Is better taken after an introductory deep learning course, such as **[fast.ai’s](https://www.fast.ai/)** **[Practical Deep Learning for Coders](https://course.fast.ai/)** or one of the programs developed by **[DeepLearning.AI](https://www.deeplearning.ai/)**
- Does not expect prior **[PyTorch](https://pytorch.org/)** or **[TensorFlow](https://www.tensorflow.org/)** knowledge, though some familiarity with either of those will help
</aside>

### **The 🤗 Book**

<img alt="book-cover" height=200 src="../../images/book_cover.jpg" id="book-cover"/>

Released February 2022

From experts at Hugging Face, learn all about Transformers and their applications to a wide range of NLP tasks.

👉 [click here to visit the book’s website](https://transformersbook.com/)

<aside>
💡 This book:

- Is written for data scientists and machine learning engineers who may have heard about the recent breakthroughs involving transformers, but are lacking an in-depth guide to help them adapt these models to their own use cases.
- Assumes you have some practical experience with training models on GPUs.
- Does not expect prior **[PyTorch](https://pytorch.org/)** or **[TensorFlow](https://www.tensorflow.org/)** knowledge, though some familiarity with either of those will help
</aside>


## 🌎 Translations

| Language | Source | Contributors |
|:---:|:---:|---|
| Spanish | [ `tutorials/ES` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/ES ) | @[lewtun](https://github.com/lewtun), @[osanseviero](https://github.com/osanseviero), @[omarespejel](https://github.com/omarespejel), @[Fabioburgos](https://github.com/Fabioburgos) |
| Japanese | [ `tutorials/JA` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/JA ) | @[Wataru-Nakata](https://github.com/Wataru-Nakata) |
| Turkish (TR) | [ `tutorials/TR` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/TR ) | @[emrecgty](https://github.com/emrecgty/) @[farukozderim](https://github.com/FarukOzderim/)  |
| Portuguese (WIP) | [ `tutorials/PT` ]( https://github.com/huggingface/education-toolkit/tree/main/tutorials/PT ) |  |

If you would like to translate the tutorials to your language, see our [TRANSLATING](https://github.com/huggingface/education-toolkit#-languages-and-translations/TRANSLATING.md) guide.

<aside>
✉️ If you have any questions, please contact violette@huggingface.co!

</aside>
