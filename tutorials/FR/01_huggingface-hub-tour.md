# Atelier : Une visite du *Hub* d'Hugging Face

<aside>

<aside>

üëã **Bienvenue !**

Nous avons assembl√© une boite √† outil que les professeurs du sup√©rieur peuvent utiliser pour pr√©parer des s√©ances de travaux dirig√©s, des cours ou des devoirs. Le contenu est autonome, de mani√®re √† ce qu'il puisse √™tre int√©grer dans un cours pr√©-existant. Le contenu est gratuit et utilise des technologies Open Source connues (`transformers`, `gradio`, etc).

Il est aussi possible de demander √† un membre de l'√©quipe d'Hugging Face de pr√©senter les tutoriels dans un de vos cours via l'initiative [*ML demo.cratization tour*](https://www.notion.so/ML-Demo-cratization-tour-with-66847a294abd4e9785e85663f5239652) !

Vous pouvez trouver tous les tutoriels et ressources que nous avons rassembl√©s [ici](https://www.notion.so/Education-Toolkit-7b4a9a9d65ee4a6eb16178ec2a4f3599) (en anglais).

</aside>

**Dur√©e :** 20 √† 40 minutes

**Objectif :** Apprendre √† utiliser efficacement le [*Hub*](http://hf.co) pour pouvoir collaborer dans l'√©cosyst√®me et au sein des √©quipes dans des projets d'apprentissage automatique.

Objectifs d'apprentissage :

- Apprendre √† conna√Ætre et explorer les plus de 50 000 mod√®les partag√©s sur le *Hub*.
- Apprendre des m√©thodes efficaces pour trouver des mod√®les et des jeux de donn√©es adapt√©s √† votre t√¢che.
- Apprendre √† contribuer et √† travailler en collaboration.
- Explorez les d√©mos d'apprentissage automatique cr√©√©es par la communaut√©.

**Format : ** TD courts ou pour des devoirs maisons.

**Public :** √âtudiants de tous horizons int√©ress√©s par l'utilisation de mod√®les existants ou par le partage de leurs propres mod√®les.

**Pr√©requis**

- Compr√©hension de haut niveau de l'apprentissage automatique.
- (Facultatif, mais encourag√©) Exp√©rience avec Git ([ressource](https://learngitbranching.js.org/))

## **Pourquoi le *Hub* ?**

Le *Hub* est une plateforme centrale o√π chacun peut partager et explorer des mod√®les, des jeux de donn√©es et des d√©monstrations d'apprentissage automatique. Le probl√®me de ¬´ r√©soudre l'IA ¬ª ne sera pas r√©solu par une seule entreprise mais par une culture de partage des connaissances et des ressources. Pour cette raison, le *Hub* vise √† construire la plus vaste collection de mod√®les, de jeux de donn√©es et de d√©mos disponibles en Open Source.

Voici quelques faits concernant le *Hub* d'Hugging Face :

- Il existe plus de 50 000 mod√®les publics.
- Il existe des mod√®les pour le traitement du langage naturel, la vision par ordinateur, l'audio/la parole et l'apprentissage par renforcement !
- Il existe des mod√®les pour plus de 180 langues.
- Toute biblioth√®que d'apprentissage automatique peut exploiter le *Hub* : de TensorFlow et PyTorch aux int√©grations avanc√©es avec spaCy, SpeechBrain et 20 autres biblioth√®ques.

## Exploration d'un mod√®le

Commen√ßons par l'exploration des mod√®les. Vous pouvez acc√©der √† 50 000 mod√®les sur [hf.co/models](http://hf.co/models). Vous verrez que [gpt2](https://huggingface.co/gpt2) est l'un des mod√®les les plus t√©l√©charg√©s. Cliquez dessus.

Lorsque vous cliquez sur un mod√®le, le site Web vous am√®ne √† la carte du mod√®le. Une carte de mod√®le est un outil qui documente et fournit des informations utiles sur un mod√®le et √©tant essentiel pour la d√©couverte et la reproductibilit√©.

L'interface comporte de nombreux composants, passons-les en revue :

[https://www.youtube.com/watch?v=XvSGPZFEjDY&feature=emb_imp_woyt](https://www.youtube.com/watch?v=XvSGPZFEjDY&feature=emb_imp_woyt)

- En haut, vous pouvez trouver diff√©rents **tags** pour des choses telles que la t√¢che (*g√©n√©ration de texte, classification d'images*, etc.), les *frameworks* (*PyTorch*, *TensorFlow*, etc.), la langue du mod√®le (*anglais*, *fran√ßais*, *etc.*) et la licence (*e.g. MIT*).

![](./images/mode_card_tags.png)

- Dans la colonne de droite, vous pouvez jouer avec le mod√®le directement dans le navigateur √† l'aide d'API d'*Inference*. Le GPT2 est un mod√®le de g√©n√©ration de texte, il va donc g√©n√©rer du texte suppl√©mentaire √† partir d'une entr√©e initiale. Essayez de taper quelque chose en anglais comme ¬´ It was a bright and sunny day ¬ª (c'√©tait une journ√©e claire et ensoleill√©e).

![](./images/model_card_inference_api.png)

- Au milieu, vous pouvez parcourir le contenu de la carte. Elle comporte des sections telles que Utilisations pr√©vues et limites, Proc√©dure d'entra√Ænement et Informations sur la citation.

![](./images/model_card_content.png)

D'o√π viennent toutes ces donn√©es ? Chez Hugging Face, tout est bas√© sur des d√©p√¥ts **Git** et est open-sourc√©. Vous pouvez cliquer sur l'onglet *Files and Versions* (ficheirs et versions) qui vous permettra de voir tous les fichiers du d√©p√¥t, y compris les poids du mod√®le. La carte est un fichier markdown **([README.md](http://README.md))** qui, en plus du contenu, contient des m√©tadonn√©es telles que les balises.

![](./images/model_card_git.png)

Comme tous les mod√®les sont des d√©p√¥ts bas√©s sur Git, vous b√©n√©ficiez d'un contr√¥le de version d√®s le d√©part. Tout comme avec GitHub, vous pouvez effectuer des op√©rations telles que le clonage, l'ajout, l'engagement, le branchement et la pouss√©e de Git. Si vous n'avez jamais utilis√© Git auparavant, nous vous sugg√©rons la [ressource](https://learngitbranching.js.org/) suivante.

**D√©fi 1** : Ouvrez le fichier `config.json` du d√©p√¥t GPT2. Le fichier config contient des hyperparam√®tres ainsi que des informations utiles pour le chargement du mod√®le. A partir de ce fichier, r√©pondez aux questions suivantes :

- Quelle est la fonction d'activation ?
- Quelle est la taille du vocabulaire ?

## **Exploration des mod√®les**

Jusqu'√† pr√©sent, nous avons explor√© un seul mod√®le. Soyons fous ! √Ä gauche de [https://huggingface.co/models](https://huggingface.co/models), vous pouvez filtrer pour diff√©rentes choses :

- **Tasks (t√¢ches) :** Il existe un support pour des dizaines de t√¢ches dans diff√©rents domaines : Vision par ordinateur, traitement du langage naturel, audio, etc. Vous pouvez cliquer sur le +13 pour voir toutes les t√¢ches disponibles.
  - **Librairies (biblioth√®ques) :** Bien que le *Hub* √©tait √† l'origine pour les mod√®les de transformateurs, le Hub a une int√©gration avec des dizaines de biblioth√®ques. Vous pouvez trouver des mod√®les de Keras, spaCy, allenNLP, et plus encore.
- **Datasets (jeux de donn√©es) :** Le *Hub* h√©berge √©galement des milliers de jeux de donn√©es, comme vous le d√©couvrirez plus tard.

![](./images/model_card_filters.png)

- **Languages (langues) :** La plupart des mod√®les du *Hub* sont li√©s au langage naturel. Vous pouvez trouver des mod√®les pour des centaines de langues, y compris des langues √† faibles ressources.

**D√©fi 2** : Combien de mod√®les de classification de *tokens* existe-t-il en anglais ?

**D√©fi 3** : Si vous deviez choisir un mod√®le espagnol pour la reconnaissance automatique de la parole, lequel choisiriez-vous ? (Il peut s'agir de n'importe quel mod√®le pour cette t√¢che et cette langue)

## Ajout d'un mod√®le

Disons que vous voulez t√©l√©charger un mod√®le sur le *Hub*. Ce mod√®le peut √™tre un mod√®le de n'importe quelle biblioth√®que ML : Scikit-learn, Keras, Transformers, etc.

Passons en revue les √©tapes :

1. Allez sur [huggingface.co/new](http://huggingface.co/new) pour cr√©er un nouveau d√©p√¥t de mod√®le. Les d√©p√¥ts que vous cr√©ez peuvent √™tre publics ou priv√©s.
2. Vous commencez avec un d√©p√¥t public qui a une carte de mod√®le. Vous pouvez t√©l√©charger votre mod√®le soit en utilisant l'interface Web, soit en le faisant avec Git. Si vous n'avez jamais utilis√© Git auparavant, nous vous sugg√©rons d'utiliser l'interface Web. Vous pouvez cliquer sur ¬´ Add File ¬ª et glisser-d√©poser les fichiers que vous souhaitez ajouter. Si vous souhaitez comprendre le flux de travail complet, optons pour l'approche Git.

    1. Installez √† la fois git et git-lfs sur votre syst√®me.
        1. Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
        2. Git-lfs: [https://git-lfs.github.com/](https://git-lfs.github.com/). Les gros fichiers doivent √™tre t√©l√©charg√©s avec Git LFS.  Git ne fonctionne pas bien d√®s que vos fichiers d√©passent quelques m√©gaoctets, ce qui est fr√©quent en apprentissage automatique. Les mod√®les d'apprentissage automatique peuvent atteindre des gigaoctets ou des t√©raoctets ! ü§Ø
    2. Clonez le d√©p√¥t que vous venez de cr√©er

        ```python
        git clone https://huggingface.co/<your-username>/<your-model-id>
        ```

    3. Allez dans le r√©pertoire et initialisez Git LFS
        1. Facultatif. Nous fournissons d√©j√† une liste d'extensions de fichiers courantes pour les gros fichiers dans `.gitattributes`, Si les fichiers que vous voulez t√©l√©charger ne sont pas inclus dans le fichier `.gitattributes`, vous pourriez avoir besoin comme indiqu√© ici : Vous pouvez le faire avec

            ```python
            git lfs track "*.your_extension"
            ```

            ```python
             git lfs install
            ```

    4. Ajoutez vos fichiers au d√©p√¥t. Les fichiers d√©pendent du *framework*/des biblioth√®ques que vous utilisez. Globalement, l'important est que vous fournissiez tous les artefacts n√©cessaires au chargement du mod√®le. Par exemple :
        1. Pour TensorFlow, vous pourriez vouloir charger un fichier SavedModel ou `h5`.
        2. Pour PyTorch, habituellement, c'est un `pytorch_model.bin`.
        3. Pour Scikit-Learn, il s'agit g√©n√©ralement d'un fichier `joblib`.

        Voici un exemple en Python de sauvegarde d'un fichier mod√®le Scikit-Learn.

        ```python
        from sklearn import linear_model
        reg = linear_model.LinearRegression()
        reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])

        from joblib import dump, load
        dump(reg, 'model.joblib')
        ```

    5. Commitez et poussez vos fichiers (assurez-vous que le fichier sauvegard√© se trouve dans le d√©p√¥t).

    ```python
    git add .
    git commit -m "First model version"
    git push
    ```

Et c'est termin√© ! Vous pouvez v√©rifier votre d√©p√¥t avec tous les fichiers r√©cemment ajout√©s !

![](./images/model_card_updated_repo.png)

L'interface utilisateur vous permet d'explorer les fichiers du mod√®le et les commits et de voir la diff√©rence introduite par chaque commit.

**D√©fi 4** : C'est votre tour ! T√©l√©chargez un mod√®le fictif de la biblioth√®que de votre choix.

Maintenant que le mod√®le est dans le *Hub*, les autres peuvent le trouver ! Vous pouvez √©galement collaborer facilement avec d'autres personnes en cr√©ant une organisation. L'h√©bergement via le *Hub* permet √† une √©quipe de mettre √† jour les d√©p√¥ts et de faire des choses auxquelles vous √™tes peut-√™tre habitu√©, comme le travail en branches et le travail collaboratif. Le *Hub* permet √©galement le versionnage de vos mod√®les : si un *checkpoint* du mod√®le est soudainement rompu, vous pouvez toujours revenir √† une version pr√©c√©dente.

En haut du `README`, vous pouvez trouver quelques m√©tadonn√©es. Vous ne trouverez que la licence pour l'instant, mais vous pouvez ajouter d'autres choses. Essayons-en quelques-unes :

```yaml
 tags:
- es       #¬†Cela sera automatiquement d√©tect√© comme une balise de langue.
- bert     #¬†Vous pouvez avoir des balises suppl√©mentaires pour le filtrage.
- text-classification #¬†Cela sera automatiquement d√©tect√© comme une √©tiquette de t√¢che.
datasets:
- llamas # Ce lien renverra √† un jeu de donn√©es sur le Hub, s'il existe.
```

**D√©fi 5** : En utilisant la [documentation](https://huggingface.co/docs/hub/model-repos#how-are-model-tags-determined), changez l'exemple par d√©faut dans le *widget*.

Les m√©tadonn√©es permettent aux gens de d√©couvrir votre mod√®le rapidement. Votre mod√®le appara√Ætra maintenant lorsque vous recherchez des mod√®les de classification de texte en espagnol. Le mod√®le appara√Ætra √©galement lorsque vous regarderez le jeu de donn√©es.

Attendez... les jeux de donn√©es ?

## Jeux de donn√©es

Avec les pipelines d'apprentissage automatique, vous disposez g√©n√©ralement d'un jeu de donn√©es pour entra√Æner le mod√®le. Le *Hub* h√©berge environ 5000 jeux de donn√©es qui sont en libre acc√®s et gratuits pour une utilisation dans de nombreux domaines. En plus de cela, la  [biblioth√®que](https://huggingface.co/docs/datasets/) `datasets` permet d'utiliser facilement ces jeux de donn√©es, y compris les plus grands, en utilisant des fonctionnalit√©s tr√®s pratiques comme le streaming. Ce TD ne traitera pas de la biblioth√®que mais il explique comment l'explorer.

Comme pour les mod√®les, vous pouvez vous rendre sur [https://hf.co/datasets](https://hf.co/datasets). A gauche, vous pouvez trouver diff√©rents filtres bas√©s sur la t√¢che, la licence, et la taille de l'ensemble de donn√©es.

Explorons le jeu de donn√©es [GLUE](https://huggingface.co/datasets/glue), qui est un jeu de donn√©es c√©l√®bre utilis√© pour tester les performances des mod√®les de traitement du langage naturel.

- Comme pour les d√©p√¥ts de mod√®les, vous avez une carte de jeu de donn√©es qui documente le jeu de donn√©es. Si vous faites d√©filer un peu vers le bas, vous trouverez des √©l√©ments tels que le r√©sum√©, la structure, et plus encore.

![](./images/datasets_card.png)

- En haut, vous pouvez explorer une partie du jeu de donn√©es directement dans le navigateur. Le jeu de donn√©es GLUE est divis√© en plusieurs sous-jeux (ou sous-ensembles) que vous pouvez s√©lectionner, tels que COLA et QNLI.

  ![](./images/datasets_slices.png)

- √Ä droite de la carte du jeu de donn√©es, vous pouvez voir une liste des mod√®les entra√Æn√©s sur ce jeu de donn√©es.

![](./images/datasets_models_trained.png)

**D√©fi 6**. Recherchez le jeu de donn√©es Common Voice. R√©pondez √† ces questions :

- Sur quelles t√¢ches le jeu de donn√©es Common Voice peut-il √™tre utilis√© ?
- Combien de langues sont couvertes dans ce jeu de donn√©es ?
- Quelles sont les subdivisions du jeu de donn√©es ?

## D√©mos d'apprentissage automatique

Partager vos mod√®les et vos jeux de donn√©es, c'est bien, mais cr√©er une d√©mo interactive et accessible au public, c'est encore mieux. Les d√©mos de mod√®les sont une partie de plus en plus importante de l'√©cosyst√®me. Les d√©mos permettent :

- Aux d√©veloppeurs de mod√®les de **pr√©senter** facilement leur travail √† un large public, par exemple dans le cadre de pr√©sentations aux parties prenantes, de conf√©rences et de projets de cours.
- D'augmenter la **reproductibilit√©** en abaissant la barri√®re pour tester un mod√®le.
- De partager avec un public non technique **l'impact d'un mod√®le**.
- Construire un **portfolio** de projets d'apprentissage automatique.

Il existe des *frameworks* Python Open-Source tels que Gradio et Streamlit qui permettent de construire ces d√©mos tr√®s facilement, et des outils tels que [Spaces] (http://hf.co/spaces/launch) qui permettent de les h√©berger et de les partager. Comme TD suivant, nous recommandons de suivre le tutoriel **Cr√©ez et h√©bergez des d√©monstrations d'apprentissage automatique avec Gradio et Hugging Face**.

> Dans ce tutoriel, vous apprendrez √† :
>
> - Explorer les d√©mos cr√©√©es par la communaut√©.
> - Construire une d√©mo rapide pour votre mod√®le d'apprentissage automatique en Python en utilisant la biblioth√®que `gradio`.
> H√©berger les d√©mos gratuitement avec *Spaces*.
> Ajoutez votre d√©mo √† l'organisation Hugging Face pour votre classe ou conf√©rence.
>
> ***Dur√©e : 20-40 minutes***
>
> üëâ¬†[cliquez ici pour acc√©der au tutoriel](https://colab.research.google.com/github.com/huggingface/education-toolkit/tree/main/02_ml-demos-with-gradio.ipynb)
