# 🤗 Boite à Outil Éducative

<aside>

👋 **Bienvenue !**

Nous avons assemblé une boite à outil que les professeurs du supérieur peuvent utiliser pour préparer des séances de travaux dirigés, des cours ou des devoirs. Le contenu est autonome, de manière à ce qu'il puisse être intégrer dans un cours pré-existant. Le contenu est gratuit et utilise des technologies Open Source connues (`transformers`, `gradio`, etc).

Il est aussi possible de demander à un membre de l'équipe d'Hugging Face de présenter les tutoriels dans un de vos cours via l'initiative [ML demo.cratization tour](https://www.notion.so/ML-Demo-cratization-tour-with-66847a294abd4e9785e85663f5239652) !

En dehors de ces tutoriels, nous mettons aussi à disposition d'autres ressources permettant d'aller plus loin dans le ML ou encore de vous assister dans la création de nouveau contenu de cours.


</aside>

## **Notre catalogue de tutoriels**

### 1️⃣ Une visite à travers le Hub d'Hugging Face

> Dans ce tutoriel, vous allez :
>
> - Explorer plus de 30,000 modèles disponibles dans le Hub.
> - Apprendre des manières efficaces pour trouver le bon modèle et le bon dataset selon vos besoins.
> - Découvrir comment contribuer et travailler en équipe au cours de vos projets de ML
>
> **_Durée : 20-40 minutes_**
>
> 👉 [Cliquer ici pour accéder au tutoriel (en anglais)](https://github.com/huggingface/education-toolkit/blob/main/01_huggingface-hub-tour.md) ou 👩‍🏫 [aux slides du cours (en anglais)](https://docs.google.com/presentation/d/1zQqpFTcpNLV7haj2Inw2qKHq8DjfZEaiObW1ZkLvPWM/edit?usp=sharing).

### 2️⃣ Construisez et hébergez des démos de Machine Learning avec Gradio & Hugging Face

> Dans ce tutoriel, vous allez :
>
> - Découvrir des démos de ML créés par la communauté.
> - Construire une brève démonstration de votre modèle de ML en Python avec la bibliothèque `gradio`.  
> - Héberger gratuitement ces démos en utilisant Hugging Face Spaces
> - Ajouter votre démo à Hugging Face org pour votre cours ou conférence.
>
> **_Durée : 20-40 minutes_**
>
> 👉 [Cliquer ici pour accéder au tutoriel (en anglais)](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/02_ml-demos-with-gradio.ipynb) ou 👩‍🏫 [aux slides du cours (en anglais) ](https://docs.google.com/presentation/d/14EU_xjtINXtpidWLnUvfcEpmxN46ORS-PLpwfUf8C1I/edit?usp=sharing).

### 3️⃣ Débuter avec les transformers

> Dans ce tutoriel, vous allez apprendre que :
>
> - Les réseaux de neurones Transformers peuvent être utilisés pour s'attaquer à un large panel de tâches, en NLP et au delà.
> - L'apprentissage par transfert (Transfer Learning) permet d'adapter les Transformers à une tâche particulière.
> - La fonction `pipeline()` de la bibliothèque `transformers` peut être utilisée pour réaliser des inférences avec tous les modèles du [Hub d'Hugging Face](https://huggingface.co/models).
>
> Ce tutoriel est basé sur notre premier livre O'Reilly *[Natural Language Processing with Transformers](https://transformersbook.com/)* - Jetez-y un coup d'oeil si vous souhaitez en apprendre davantage sur le sujet.
>
> **_Durée: 30-45 minutes_**
>
> 👉 [Cliquer ici pour accéder au tutoriel](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/tutorials/FR/03_d%C3%A9buter-avec-les-transformers.ipynb)

## **D'autres ressources pour poursuivre votre apprentissage !**

### **Le Cours 🤗**

Nous fournissons un cours (gratuit et sans publicités) qui traite du traitement naturel du langage (NLP) en utilisant les bibliothèques de l'écosysteme **[Hugging Face](https://huggingface.co/)** ecosystem.

👉 [Cliquer ici pour accéder au cours](https://huggingface.co/course/chapter1/1)

<aside>
💡 Ce cours :

- Nécessite une bonne connaissance de Python
- Est plus facile en ayant préalablement suivi un cours introductif à l'apprentissage profond (Deep Learning) **[fast.ai’s](https://www.fast.ai/)** **[Practical Deep Learning for Coders](https://course.fast.ai/)** ou l'un des programmes développés par **[DeepLearning.AI](https://www.deeplearning.ai/)**
- Ne suppose pas de connaissances préalables de **[PyTorch](https://pytorch.org/) **ou** [TensorFlow](https://www.tensorflow.org/)**, même si être famillier avec l'un des deux peut faciliter la compréhension.
</aside>

### **Le Livre 🤗**

<img alt="book-cover" height=200 src="../../images/book_cover.jpg" id="book-cover"/>

Sorti en février 2022

Apprenez tout des Transformers ainsi que de leurs applications à un large panel d'applications en NLP. Écrits par les experts de Hugging Face.

👉 [Cliquer ici pour visiter le site du livre](https://transformersbook.com/)

<aside>
💡 Ce livre :

- Est écrit pour des data scientists et des ingénieurs en machine learning qui seraient au fait des dernières avancées majeures impliquant les transformers, mais à qui il manquerait un guide détaillé afin de les aider dans l'adaptation de ces modèles à leurs besoins.
- Suppose que vous ayez une expérience pratique dans l'entrainement de modèles sur GPU
- Ne suppose pas de connaissances préalables de **[PyTorch](https://pytorch.org/) **ou** [TensorFlow](https://www.tensorflow.org/)**, même si être famillier avec l'un des deux peut faciliter la compréhension.

<aside>
✉️ Si vous avez la moindre question, contactez violette@huggingface.co !

</aside>
