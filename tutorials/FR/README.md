# ğŸ¤— Boite Ã  Outil Ã‰ducative

<aside>

ğŸ‘‹ **Bienvenue !**

Nous avons assemblÃ© une boite Ã  outil que les professeurs du supÃ©rieur peuvent utiliser pour prÃ©parer des sÃ©ances de travaux dirigÃ©s, des cours ou des devoirs. Le contenu est autonome, de maniÃ¨re Ã  ce qu'il puisse Ãªtre intÃ©grer dans un cours prÃ©-existant. Le contenu est gratuit et utilise des technologies Open Source connues (`transformers`, `gradio`, etc).

Il est aussi possible de demander Ã  un membre de l'Ã©quipe d'Hugging Face de prÃ©senter les tutoriels dans un de vos cours via l'initiative [*ML demo.cratization tour*](https://www.notion.so/ML-Demo-cratization-tour-with-66847a294abd4e9785e85663f5239652) !

En dehors de ces tutoriels, nous mettons aussi Ã  disposition d'autres ressources permettant d'aller plus loin dans l'apprentissage automatique ou encore de vous assister dans la crÃ©ation de nouveau contenu de cours.


</aside>

## **Notre catalogue de tutoriels**

### 1ï¸âƒ£Â Une visite Ã  travers le *Hub* d'Hugging Face

> Dans ce tutoriel, vous allez :
>
> - Explorer plus de 50,000 modÃ¨les disponibles dans le *Hub*.
> - Apprendre des maniÃ¨res efficaces Ã  trouver le bon modÃ¨le et le bon jeu de donnÃ©es correspondant Ã  vos besoins.
> - DÃ©couvrir comment contribuer et travailler en Ã©quipe au cours de vos projets d'apprentissage automatique.
>
> **_DurÃ©e : 20-40 minutes_**
>
> ğŸ‘‰Â [Cliquer ici pour accÃ©der au tutoriel](https://github.com/huggingface/education-toolkit/blob/main/01_huggingface-hub-tour.md) ou ğŸ‘©â€ğŸ« [aux diapositives du cours (en anglais)](https://docs.google.com/presentation/d/1zQqpFTcpNLV7haj2Inw2qKHq8DjfZEaiObW1ZkLvPWM/edit?usp=sharing).

### 2ï¸âƒ£Â Construisez et hÃ©bergez des dÃ©mos l'apprentissage automatique avec Gradio & Hugging Face

> Dans ce tutoriel, vous allez :
>
> - DÃ©couvrir des dÃ©mos d'apprentissage automatique crÃ©Ã©s par la communautÃ©.
> - Construire une brÃ¨ve dÃ©monstration de votre modÃ¨le d'apprentissage automatique en Python avec la bibliothÃ¨que `gradio`.  
> - HÃ©berger gratuitement ces dÃ©mos en utilisant Hugging Face *Spaces*.
> - Ajouter votre dÃ©mo Ã  Hugging Face org pour votre cours ou confÃ©rence.
>
> **_DurÃ©e : 20-40 minutes_**
>
> ğŸ‘‰Â [Cliquer ici pour accÃ©der au tutoriel](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/02_ml-demos-avec-gradio.ipynb) ou ğŸ‘©â€ğŸ« [aux diapositives du cours (en anglais) ](https://docs.google.com/presentation/d/14EU_xjtINXtpidWLnUvfcEpmxN46ORS-PLpwfUf8C1I/edit?usp=sharing).

### 3ï¸âƒ£Â DÃ©buter avec les transformers

> Dans ce tutoriel, vous allez apprendre que :
>
> - Les rÃ©seaux de neurones de type *transformers* peuvent Ãªtre utilisÃ©s pour s'attaquer Ã  un large panel de tÃ¢ches, en traitement du langage naturel et au delÃ .
> - L'apprentissage par transfert (*transfer learning*) permet d'adapter les transformers Ã  une tÃ¢che particuliÃ¨re.
> - La fonction `pipeline()`Â de la bibliothÃ¨que `transformers`Â peut Ãªtre utilisÃ©e pour rÃ©aliser des infÃ©rences avec tous les modÃ¨les duÂ [*Hub* d'Hugging Face](https://huggingface.co/models).
>
> Ce tutoriel est basÃ© sur notre premier livre O'ReillyÂ *[Natural Language Processing with Transformers](https://transformersbook.com/)*. Jetez-y un coup d'oeil si vous souhaitez en apprendre davantage sur le sujet.
>
> **_DurÃ©e: 30-45 minutes_**
>
> ğŸ‘‰Â [Cliquer ici pour accÃ©der au tutoriel](https://colab.research.google.com/github/huggingface/education-toolkit/blob/main/tutorials/FR/03_d%C3%A9buter-avec-les-transformers.ipynb)

## **D'autres ressources pour poursuivre votre apprentissage !**

### **Le Cours ğŸ¤—**

Nous fournissons un cours (gratuit et sans publicitÃ©s) qui traite du traitement naturel du langage (NLP) en utilisant les bibliothÃ¨ques de l'Ã©cosystemeÂ **[Hugging Face](https://huggingface.co/)**.

ğŸ‘‰Â [Cliquer ici pour accÃ©der au cours](https://huggingface.co/course/fr/chapter1/1)

<aside>
ğŸ’¡ Ce cours :

- NÃ©cessite une bonne connaissance de Python.
- Est plus facile en ayant prÃ©alablement suivi un cours introductif Ã  l'apprentissage profond (*Deep Learning*) comme celui deÂ **[fast.aiâ€™s](https://www.fast.ai/)**Â (*[Practical Deep Learning for Coders](https://course.fast.ai/)*)Â ou l'un des programmes dÃ©veloppÃ©s parÂ **[DeepLearning.AI](https://www.deeplearning.ai/)**.
- Ne suppose pas de connaissances prÃ©alables deÂ **[PyTorch](https://pytorch.org/) **ou** [TensorFlow](https://www.tensorflow.org/)** mÃªme si Ãªtre famillier avec l'un des deux peut faciliter la comprÃ©hension.
</aside>

### **Le Livre ğŸ¤—**

<img alt="book-cover" height=200 src="../../images/book_cover.jpg" id="book-cover"/>

Sorti en fÃ©vrier 2022.  

Apprenez tous des *Transformers* ainsi que de leurs applications Ã  un large panel de tÃ¢ches de traitement du langage naturel. Ã‰crits par les experts de Hugging Face.

ğŸ‘‰Â [Cliquer ici pour visiter le site du livre](https://transformersbook.com/)

<aside>
ğŸ’¡ Ce livre :

- Est Ã©crit pour des data scientists et des ingÃ©nieurs en apprentissage automatique qui seraient au fait des derniÃ¨res avancÃ©es majeures impliquant les *transformers* mais Ã  qui il manquerait un guide dÃ©taillÃ© afin de les aider dans l'adaptation de ces modÃ¨les Ã  leurs besoins.
- Suppose que vous ayez une expÃ©rience pratique dans l'entrainement de modÃ¨les sur GPU.
- Ne suppose pas de connaissances prÃ©alables deÂ **[PyTorch](https://pytorch.org/) **ou** [TensorFlow](https://www.tensorflow.org/)** mÃªme si Ãªtre famillier avec l'un des deux peut faciliter la comprÃ©hension.

<aside>
âœ‰ï¸ Si vous avez la moindre question, contactez violette@huggingface.co !

</aside>
